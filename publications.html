---
layout: default
title: Publications
---

<h1>Publications</h1>

<div class="publications">

  <div class="pub-year">2025</div>

  <div class="pub-entry">
    <div class="pub-info">
      <p class="pub-title">A dynamic likelihood approach to filtering transport processes: advection-diffusion dynamics</p>
      <p class="pub-authors"> <u>Johannes Krotz</u>,Juan M. Restrepo, Jorge Ramirez</p>
      <p class="pub-journal"><em>Journal of Computational Physics</em></p>
    </div>

    <div class="pub-buttons">
      <button class="pub-btn toggle-btn" data-target="abs-1">Abstract</button>
      <button class="pub-btn toggle-btn" data-target="bib-1">BibTeX</button>
      <a class="pub-btn" href="https://doi.org/10.1016/j.jcp.2025.114089" target="_blank">URL</a>
     <button class="pub-btn toggle-btn" data-target="sum-1">In Simple Terms</button>
    </div>

    <div class="pub-toggle hidden" id="abs-1">
      <p>
      A Bayesian data assimilation scheme is formulated for advection-dominated advective and diffusive evolutionary problems, based upon the Dynamic Likelihood (DLF) approach to filtering. The DLF was developed specifically for hyperbolic problems –waves–, and in this paper, it is extended via a split step formulation, to handle advection-diffusion problems. In the dynamic likelihood approach, observations and their statistics are used to propagate probabilities along characteristics, evolving the likelihood in time. The estimate posterior thus inherits phase information. For advection-diffusion the advective part of the time evolution is handled on the basis of observations alone, while the diffusive part is informed through the model as well as observations. We expect, and indeed show here, that in advection-dominated problems, the DLF approach produces better estimates than other assimilation approaches, particularly when the observations are sparse and have low uncertainty. The added computational expense of the method is cubic in the total number of observations over time, which is on the same order of magnitude as a standard Kalman filter and can be mitigated by bounding the number of forward propagated observations, discarding the least informative data.</p>
    </div>

    <div class="pub-toggle hidden" id="bib-1">
      <pre>@article{KROTZ_2025_DynamicLikelihoodFilter,
title = {A dynamic likelihood approach to filtering transport processes: advection-diffusion dynamics},
journal = {Journal of Computational Physics},
volume = {536},
pages = {114089},
year = {2025},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2025.114089},
url = {https://www.sciencedirect.com/science/article/pii/S0021999125003729},
author = {Johannes Krotz and Juan M. Restrepo and Jorge Ramirez},
keywords = {Data assimilation, Bayesian estimation, Dynamic likelihood filter, 
Advection-diffusion, Transport, Kalman filter},
abstract = {A Bayesian data assimilation scheme is formulated for advection-dominated advective 
        and diffusive evolutionary problems, based upon the Dynamic Likelihood (DLF) approach to 
        filtering. The DLF was developed specifically for hyperbolic problems –waves–, and in this
        paper, it is extended via a split step formulation, to handle advection-diffusion problems. 
        In the dynamic likelihood approach, observations and their statistics are used to propagate 
        probabilities along characteristics, evolving the likelihood in time. The estimate posterior
        thus inherits phase information. For advection-diffusion the advective part of the time 
        evolution is handled on the basis of observations alone, while the diffusive part is informed 
        through the model as well as observations. We expect, and indeed show here, that in 
        advection-dominated problems, the DLF approach produces better estimates than other 
        assimilation approaches, particularly when the observations are sparse and have low 
        uncertainty. The added computational expense of the method is cubic in the total number of 
        observations over time, which is on the same order of magnitude as a standard Kalman filter 
        and can be mitigated by bounding the number of forward propagated observations, discarding 
        the least informative data.}}}
        </pre>
    </div>

<div class="pub-toggle hidden" id="sum-1">
  <p>
    Imagine trying to predict how sunlight travels through Earth’s atmosphere, how radiation moves inside a nuclear reactor, 
    or how heat from a laser interacts with a dense plasma. All of these processes involve <strong>particles moving, bouncing, 
    and sometimes getting absorbed</strong> as they travel through a medium. Modeling these processes accurately is a monumental challenge. 
  </p>

  <p>
    Traditionally, scientists have relied on two approaches: <em>deterministic methods</em>, which translate physics into large systems 
    of equations, and <em>Monte Carlo methods</em>, which simulate particle paths randomly. Each has strengths and weaknesses. Deterministic 
    methods can be precise but become prohibitively expensive at high resolution. Monte Carlo is flexible and natural for complex geometries, 
    but it’s noisy and often requires an enormous number of samples to be reliable. 
  </p>

  <h3>The Core Idea: Pre- and Post-Collision Particles</h3>
  <p>
    The hybrid method presented in this paper blends the two approaches by recognizing that particles behave differently depending 
    on whether they’ve collided yet. 
  </p>
  <ul>
    <li><strong>Pre-collision (uncollided):</strong> particles stream like rays of light. Their paths are straightforward, and Monte Carlo 
    can handle them efficiently — essentially like ray tracing.</li>
    <li><strong>Post-collision (collided):</strong> once particles scatter, their distribution becomes smoother and more diffuse. A deterministic 
    solver is better suited here, capturing the averaged behavior without tracking every random path.</li>
  </ul>
  <p>
    A clever <em>relabeling step</em> keeps the balance by periodically shifting some particles back into the pre-collision group, ensuring 
    the method stays both accurate and efficient over time.
  </p>

  <h3>Results &amp; Takeaways</h3>
  <p>
    Across standard benchmark problems, the hybrid method consistently delivered <strong>greater accuracy at significantly lower cost</strong>. 
    Unlike pure deterministic solvers, it avoided artificial streaks (“ray effects”), and unlike pure Monte Carlo, it didn’t require massive 
    sample counts. Overall, it achieved comparable or better accuracy with <em>about an order of magnitude less computational complexity</em>.
  </p>
  <p>
    This is more than a technical curiosity — it has direct relevance to <strong>nuclear engineering</strong>, <strong>astrophysics</strong>, 
    <strong>medical physics</strong>, and <strong>fusion research</strong>. Anywhere particles stream and scatter through matter, this method 
    can provide faster, cleaner, and more reliable simulations. 
  </p>

  <h3>Looking Ahead</h3>
  <p>
    While the current work focuses on single-energy problems, the approach naturally extends to more complex cases, such as multi-energy 
    neutron transport or nonlinear radiative transfer in astrophysics. Future versions may even include adaptive strategies to automatically 
    balance the two solvers as the simulation evolves. 
  </p>

  <p>
    <em>In short:</em> By treating particles before and after collisions differently — Monte Carlo for the sharp, ray-like stage, and deterministic 
    solvers for the scattered stage — this hybrid method achieves what neither approach can do alone: <strong>faster, more accurate, 
    and more practical simulations of particle transport</strong>.
  </p>
</div>



  </div>

</div>



<div class="pub-year">2024</div>

<div class="pub-entry">
  <div class="pub-info">
    <p class="pub-title">A hybrid Monte Carlo, discontinuous Galerkin method for linear kinetic transport equations</p>
    <p class="pub-authors"><u>Johannes Krotz</u>, Cory D. Hauck, Ryan G. McClarren</p>
    <p class="pub-journal"><em>Journal of Computational Physics</em></p>
  </div>

  <div class="pub-buttons">
    <button class="pub-btn toggle-btn" data-target="abs-2">Abstract</button>
    <button class="pub-btn toggle-btn" data-target="bib-2">BibTeX</button>
    <a class="pub-btn" href="https://doi.org/10.1016/j.jcp.2024.113253" target="_blank">URL</a>
    <button class="pub-btn toggle-btn" data-target="sum-2">In Simple Terms</button>
  </div>

  <div class="pub-toggle hidden" id="abs-2">
    <p>We present a hybrid method for time-dependent particle transport problems that combines Monte Carlo (MC) estimation with deterministic solutions based on discrete ordinates. For spatial discretizations, the MC algorithm computes a piecewise constant solution and the discrete ordinates use bilinear discontinuous finite elements. From the hybridization of the problem, the resulting problem solved by Monte Carlo is scattering free, resulting in a simple, efficient solution procedure. Between time steps, we use a projection approach to “relabel” collided particles as uncollided particles. From a series of standard 2-D Cartesian test problems we observe that our hybrid method has improved accuracy and reduction in computational complexity of approximately an order of magnitude relative to standard discrete ordinates solutions.</p>
  </div>

  <div class="pub-toggle hidden" id="bib-2">
    <pre>@article{KROTZ_2024_HybridMCDG,
title = {A hybrid Monte Carlo, discontinuous Galerkin method for linear kinetic transport equations},
journal = {Journal of Computational Physics},
volume = {514},
pages = {113253},
year = {2024},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2024.113253},
url = {https://www.sciencedirect.com/science/article/pii/S0021999124005011},
author = {Johannes Krotz and Cory D. Hauck and Ryan G. McClarren},
keywords = {Hybrid stochastic-deterministic method, Monte Carlo, Kinetic equations, Particle transport},
abstract = {We present a hybrid method for time-dependent particle transport problems that combines
         Monte Carlo (MC) estimation with deterministic solutions based on discrete ordinates. For 
         spatial discretizations, the MC algorithm computes a piecewise constant solution and the 
         discrete ordinates use bilinear discontinuous finite elements. From the hybridization of 
         the problem, the resulting problem solved by Monte Carlo is scattering free, resulting in 
         a simple, efficient solution procedure. Between time steps, we use a projection approach to 
         “relabel” collided particles as uncollided particles. From a series of standard 2-D Cartesian
         test problems we observe that our hybrid method has improved accuracy and reduction in 
         computational complexity of approximately an order of magnitude relative to standard discrete
         ordinates solutions.}}
    </pre>
  </div>

  <div class="pub-toggle hidden" id="sum-2">
    <p>TBD</p>
  </div>
</div>




<div class="pub-year">2023</div>

<div class="pub-entry">
  <div class="pub-info">
    <p class="pub-title">Variable resolution Poisson-disk sampling for meshing discrete fracture networks</p>
    <p class="pub-authors"><u>Johannes Krotz</u>, Matthew R. Sweeney, Carl W. Gable, Jeffrey D. Hyman, Juan M. Restrepo </p>
    <p class="pub-journal"><em>Journal of Computational and Applied Mathematics</em></p>
  </div>

  <div class="pub-buttons">
    <button class="pub-btn toggle-btn" data-target="abs-3">Abstract</button>
    <button class="pub-btn toggle-btn" data-target="bib-3">BibTeX</button>
    <a class="pub-btn" href="https://doi.org/10.1016/j.cam.2022.114094" target="_blank">URL</a>
    <button class="pub-btn toggle-btn" data-target="sum-3">In Simple Terms</button>
  </div>

  <div class="pub-toggle hidden" id="abs-3">
    <p>We present the near-Maximal Algorithm for Poisson-disk Sampling (nMAPS) to generate point distributions for variable resolution Delaunay triangular and tetrahedral meshes in two and three-dimensions, respectively. nMAPS consists of two principal stages. In the first stage, an initial point distribution is produced using a cell-based rejection algorithm. In the second stage, holes in the sample are detected using an efficient background grid and filled in to obtain a near-maximal covering. Extensive testing shows that nMAPS generates a variable resolution mesh in linear run time with the number of accepted points. We demonstrate nMAPS capabilities by meshing three-dimensional discrete fracture networks (DFN) and the surrounding volume. The discretized boundaries of the fractures, which are represented as planar polygons, are used as the seed of 2D-nMAPS to produce a conforming Delaunay triangulation. The combined mesh of the DFN is used as the seed for 3D-nMAPS, which produces conforming Delaunay tetrahedra surrounding the network. Under a set of conditions that naturally arise in maximal Poisson-disk samples and are satisfied by nMAPS, the two-dimensional Delaunay triangulations are guaranteed to only have well-behaved triangular faces. While nMAPS does not provide triangulation quality bounds in more than two dimensions, we found that low-quality tetrahedra in 3D are infrequent, can be readily detected and removed, and a high quality balanced mesh is produced.</p>
  </div>

  <div class="pub-toggle hidden" id="bib-3">
    <pre>@article{KROTZ_2022_PoissonDiskDFN,
title = {Variable resolution Poisson-disk sampling for meshing discrete fracture networks},
journal = {Journal of Computational and Applied Mathematics},
volume = {407},
pages = {114094},
year = {2022},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2022.114094},
url = {https://www.sciencedirect.com/science/article/pii/S0377042722000073},
author = {Johannes Krotz and Matthew R. Sweeney and Carl W. Gable and Jeffrey D. Hyman and Juan M. Restrepo},
keywords = {Discrete fracture network, Maximal Poisson-disk sampling, Mesh generation, Conforming Delaunay triangulation},
abstract = {We present the near-Maximal Algorithm for Poisson-disk Sampling (nMAPS) to generate point 
        distributions for variable resolution Delaunay triangular and tetrahedral meshes in two and 
        three-dimensions, respectively. nMAPS consists of two principal stages. In the first stage, 
        an initial point distribution is produced using a cell-based rejection algorithm. In the 
        second stage, holes in the sample are detected using an efficient background grid and filled
        in to obtain a near-maximal covering. Extensive testing shows that nMAPS generates a variable 
        resolution mesh in linear run time with the number of accepted points. We demonstrate nMAPS 
        capabilities by meshing three-dimensional discrete fracture networks (DFN) and the surrounding 
        volume. The discretized boundaries of the fractures, which are represented as planar polygons, are 
        used as the seed of 2D-nMAPS to produce a conforming Delaunay triangulation. The combined mesh
        of the DFN is used as the seed for 3D-nMAPS, which produces conforming Delaunay tetrahedra 
        surrounding the network. Under a set of conditions that naturally arise in maximal Poisson-disk 
        samples and are satisfied by nMAPS, the two-dimensional Delaunay triangulations are guaranteed
        to only have well-behaved triangular faces. While nMAPS does not provide triangulation quality 
        bounds in more than two dimensions, we found that low-quality tetrahedra in 3D are infrequent, 
        can be readily detected and removed, and a high quality balanced mesh is produced.}}
   </pre>
  </div>

  <div class="pub-toggle hidden" id="sum-3">
    <p>TBD</p>
  </div>
</div>

<!-- Template

<div class="pub-year">2023</div>

<div class="pub-entry">
  <div class="pub-info">
    <p class="pub-title">High-Order Methods for Neutron Transport</p>
    <p class="pub-authors"><u>Johannes Krotz</u>, Author B, Author C</p>
    <p class="pub-journal"><em>Annals of Nuclear Engineering</em></p>
  </div>

  <div class="pub-buttons">
    <button class="pub-btn toggle-btn" data-target="abs-2">Abstract</button>
    <button class="pub-btn toggle-btn" data-target="bib-2">BibTeX</button>
    <a class="pub-btn" href="https://journal.com/paper456" target="_blank">URL</a>
    <button class="pub-btn toggle-btn" data-target="sum-2">In Simple Terms</button>
  </div>

  <div class="pub-toggle hidden" id="abs-2">
    <p>This paper introduces a new high-order discretization method for neutron transport in multigroup settings with improved convergence guarantees.</p>
  </div>

  <div class="pub-toggle hidden" id="bib-2">
    <pre>@article{krotz2023neutron,
  title={High-Order Methods for Neutron Transport},
  author={Johannes Krotz and Author B and Author C},
  journal={Annals of Nuclear Engineering},
  year={2023}
}</pre>
  </div>

  <div class="pub-toggle hidden" id="sum-2">
    <p>Neutron transport helps us simulate nuclear reactors. This paper improves how these simulations are done, making them faster and more accurate.</p>
  </div>
</div>
-->


